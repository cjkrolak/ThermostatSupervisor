#!/usr/bin/env python3
"""
Split SARIF file by tool category to avoid duplicate category uploads.

This script processes a SARIF file generated by Codacy and splits it into
separate files by tool category to comply with GitHub's requirement that
each SARIF upload should contain only a single run per category.
"""

import json
import sys
import os
from pathlib import Path
from typing import Dict, Any


def load_sarif_file(filepath: str) -> Dict[str, Any]:
    """Load and parse SARIF file."""
    try:
        with open(filepath, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: SARIF file '{filepath}' not found.")
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON in SARIF file: {e}")
        sys.exit(1)


def get_tool_name(run: Dict[str, Any]) -> str:
    """Extract tool name from a SARIF run."""
    tool = run.get("tool", {})
    driver = tool.get("driver", {})
    return driver.get("name", "unknown")


def split_sarif_by_category(sarif_data: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    """Split SARIF data by tool category."""
    runs_by_tool = {}

    for run in sarif_data.get("runs", []):
        tool_name = get_tool_name(run)

        if tool_name not in runs_by_tool:
            # Create a new SARIF document for this tool
            runs_by_tool[tool_name] = {
                "$schema": sarif_data.get("$schema", ""),
                "version": sarif_data.get("version", "2.1.0"),
                "runs": [],
            }

        runs_by_tool[tool_name]["runs"].append(run)

    return runs_by_tool


def save_sarif_files(runs_by_tool: Dict[str, Dict[str, Any]], output_dir: str = "."):
    """Save separate SARIF files for each tool."""
    output_files = []

    for tool_name, sarif_data in runs_by_tool.items():
        # Sanitize tool name for filename
        safe_tool_name = tool_name.replace("/", "_").replace(" ", "_")
        filename = f"results-{safe_tool_name}.sarif"
        filepath = os.path.join(output_dir, filename)

        with open(filepath, "w") as f:
            json.dump(sarif_data, f, indent=2)

        output_files.append(
            {
                "tool": tool_name,
                "file": filepath,
                "results_count": sum(
                    len(run.get("results", [])) for run in sarif_data["runs"]
                ),
            }
        )

        print(
            f"Created {filepath} with {output_files[-1]['results_count']} "
            f"results for {tool_name}"
        )

    return output_files


def main():
    """Main function to process SARIF file."""
    if len(sys.argv) < 2:
        print("Usage: python split-sarif-by-category.py <sarif_file> [output_dir]")
        sys.exit(1)

    sarif_file = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) > 2 else "."

    # Create output directory if it doesn't exist
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # Load and process SARIF file
    sarif_data = load_sarif_file(sarif_file)
    print(f"Loaded SARIF file with {len(sarif_data.get('runs', []))} runs")

    # Split by tool category
    runs_by_tool = split_sarif_by_category(sarif_data)
    print(f"Found {len(runs_by_tool)} unique tools: {list(runs_by_tool.keys())}")

    # Save separate files
    output_files = save_sarif_files(runs_by_tool, output_dir)

    # Output file list for GitHub Actions
    print("::group::Generated SARIF files")
    for file_info in output_files:
        print(f"Tool: {file_info['tool']}")
        print(f"File: {file_info['file']}")
        print(f"Results: {file_info['results_count']}")
        print()
    print("::endgroup::")

    # Set output for GitHub Actions
    files_json = json.dumps([f["file"] for f in output_files])
    print(f"::set-output name=sarif_files::{files_json}")


if __name__ == "__main__":
    main()
